{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"34Y21PjEd8cO"},"outputs":[],"source":["class NeuralNetwork(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super(NeuralNetwork, self).__init__()\n","        self.layer_norm = nn.LayerNorm(input_size)\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(hidden_size, int(hidden_size*5))\n","        self.fc3 = nn.Linear(int(hidden_size*5), num_classes)\n","\n","    def forward(self, x):\n","        out = self.layer_norm(x)\n","        out = self.fc1(x)\n","        out = self.relu(out)\n","        out = self.fc2(out)\n","        out = self.relu(out)\n","        out = self.fc3(out)\n","        return out"]},{"cell_type":"code","source":["\n","# Train the model\n","num_epochs = 100\n","batch_size = 32\n","\n","# Split the data into train, validation, and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X_filtered_important, y_train_resampled, test_size=0.2, random_state=42)\n","\n","# Convert data to PyTorch tensors\n","X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n","X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n","y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n","\n","\n","# Create DataLoader for train and test sets\n","train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size)\n","\n","# Initialize the model\n","input_size = X_train.shape[1]\n","num_classes = len(y_train.unique())\n","\n","modelMLP = NeuralNetwork(input_size = input_size, hidden_size = 64, num_classes = num_classes)\n","\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(modelMLP.parameters(), lr=0.001, weight_decay=1e-5)\n","\n","\n","# Train the model\n","highest_train_accuracy = 0.0\n","highest_train_auc = 0.0\n","highest_test_accuracy = 0.0\n","highest_test_auc = 0.0\n","\n","for epoch in range(num_epochs):\n","    modelMLP.train()\n","    total_loss = 0\n","    train_outputs = []\n","    train_labels = []\n","    for inputs, labels in train_loader:\n","        optimizer.zero_grad()\n","        outputs = modelMLP(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","        train_outputs.extend(outputs.detach().cpu().numpy())\n","        train_labels.extend(labels.detach().cpu().numpy())\n","\n","    # Calculate accuracy and AUC for train dataset\n","    train_outputs = torch.tensor(train_outputs)\n","    train_labels = torch.tensor(train_labels)\n","    _, train_predicted = torch.max(train_outputs, 1)\n","    train_accuracy = accuracy_score(train_labels, train_predicted)\n","\n","    # Get softmax probabilities for train dataset\n","    train_probs = torch.softmax(train_outputs, dim=1)\n","\n","    # Calculate AUC for train dataset\n","    train_auc = roc_auc_score(train_labels, train_probs, multi_class='ovo', average='weighted')\n","\n","    # Test the model\n","    modelMLP.eval()\n","    with torch.no_grad():\n","        test_outputs = modelMLP(X_test_tensor)\n","        test_loss = criterion(test_outputs, y_test_tensor)\n","        _, predicted = torch.max(test_outputs, 1)\n","        accuracy = (predicted == y_test_tensor).sum().item() / len(y_test_tensor)\n","\n","        # Get softmax probabilities for test dataset\n","        test_probs = torch.softmax(test_outputs, dim=1)\n","\n","        # Calculate AUC for test dataset\n","        auc = roc_auc_score(y_test_tensor, test_probs, multi_class='ovo', average='weighted')\n","\n","    if train_accuracy > highest_train_accuracy:\n","        highest_train_accuracy = train_accuracy\n","    if train_auc > highest_train_auc:\n","        highest_train_auc = train_auc\n","    if accuracy > highest_test_accuracy:\n","        highest_test_accuracy = accuracy\n","    if auc > highest_test_auc:\n","        highest_test_auc = auc\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {total_loss/len(train_loader):.4f}, Train Accuracy: {train_accuracy:.4f}, Train AUC: {train_auc:.4f}, Test Loss: {test_loss.item():.4f}, Val Acc: {accuracy:.4f}, Val AUC: {auc:.4f}')\n","\n","print(f'Highest Train Accuracy: {highest_train_accuracy}, Highest Train AUC: {highest_train_auc}')\n","print(f'Highest Test Accuracy: {highest_test_accuracy}, Highest Val AUC: {highest_test_auc}')\n","\n"],"metadata":{"id":"Wyl51Vxgj6Cl"},"execution_count":null,"outputs":[]}]}